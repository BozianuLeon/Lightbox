{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = 'PL=F' #platinum\n",
    "# name = 'GC=F' #gold\n",
    "# name = 'SI=F' #silver\n",
    "# name = 'HG=F' #copper\n",
    "# name = 'PA=F' #paladium\n",
    "# name = 'CL=F' #crude oil\n",
    "# name = 'BZ=F' #brent crude oil\n",
    "name = 'NG=F' #natural gas\n",
    "\n",
    "train_end_date = '2023-07-01'\n",
    "\n",
    "name_ohlc_df = yf.download(name, start='2010-01-01', end=train_end_date)\n",
    "name_ohlc_df = name_ohlc_df.reset_index()\n",
    "\n",
    "data = {'date': name_ohlc_df.Date, 'close': name_ohlc_df.Close}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(df['date'], df['close'], linestyle='-', color='b')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature')\n",
    "plt.title(name+' Price')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = np.array(df.iloc[:,1]+np.random.randn(df.shape[0])).astype(np.float32).reshape(-1,1)\n",
    "train_size = int(0.75 * len(df))\n",
    "\n",
    "# x1 = np.array(df.iloc[:train_size,1]).astype(np.float32).reshape(-1,1)\n",
    "sequence_length = 10\n",
    "train_input = np.lib.stride_tricks.sliding_window_view(df.iloc[:train_size,1].values, sequence_length)\n",
    "val_input = np.lib.stride_tricks.sliding_window_view(df.iloc[train_size:-1,1].values, sequence_length)\n",
    "\n",
    "y1 = np.array(df.iloc[sequence_length:train_size+1,1]).T.astype(np.float32).reshape(-1,1)\n",
    "y2 = np.array(df.iloc[sequence_length+train_size:,1]).T.astype(np.float32).reshape(-1,1)\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_input[:2])\n",
    "# print()\n",
    "# print(y1[:2])\n",
    "# print(train_input.shape,y1.shape)\n",
    "\n",
    "print(val_input[:2])\n",
    "print()\n",
    "print(y2[:2])\n",
    "print(val_input.shape,y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the surrogate posterior over `keras.layers.Dense` `kernel` and `bias`.\n",
    "def posterior_mean_field(kernel_size, bias_size=0, dtype=None):\n",
    "  n = kernel_size + bias_size\n",
    "  c = np.log(np.expm1(1.))\n",
    "  return tf.keras.Sequential([\n",
    "      tfp.layers.VariableLayer(2 * n, dtype=dtype),\n",
    "      tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "          tfd.Normal(loc=t[..., :n],\n",
    "                     scale=1e-5 + tf.nn.softplus(c + t[..., n:])),\n",
    "          reinterpreted_batch_ndims=1)),\n",
    "  ])\n",
    "\n",
    "# Specify the prior over `keras.layers.Dense` `kernel` and `bias`.\n",
    "def prior_trainable(kernel_size, bias_size=0, dtype=None):\n",
    "  n = kernel_size + bias_size\n",
    "  return tf.keras.Sequential([\n",
    "      tfp.layers.VariableLayer(n, dtype=dtype),\n",
    "      tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n",
    "          tfd.Normal(loc=t, scale=1),\n",
    "          reinterpreted_batch_ndims=1)),\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(32,activation='relu'),\n",
    "  tfp.layers.DenseVariational(1 + 1, posterior_mean_field, prior_trainable, kl_weight=1/train_input.shape[0]),\n",
    "  tfp.layers.DistributionLambda(\n",
    "      # lambda t: tfd.Normal(loc=t[..., :1],scale=1e-3 + tf.math.softplus(0.001 * t[...,1:]))),\n",
    "      lambda t: tfd.StudentT(df=4,loc=t[..., :1],scale=1e-3 + 0.001*tf.math.softplus(t[...,1:]))),\n",
    "      # lambda t: tfd.TwoPieceStudentT(df=5,loc=t[..., :1],scale=1e-3 + 0.1*tf.math.softplus(t[...,1:2]),skewness=0.1 + 0.1*tf.math.softplus(t[...,2:]))),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negloglik = lambda y, rv_y: -rv_y.log_prob(y)\n",
    "\n",
    "# Do inference.\n",
    "model.compile(optimizer=tf.optimizers.legacy.Adam(learning_rate=0.01), loss=negloglik)\n",
    "model.fit(train_input, y1, epochs=1500, verbose=1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profit.\n",
    "yhat = model(val_input)\n",
    "# [print(np.squeeze(w.numpy())) for w in model.weights];\n",
    "assert isinstance(yhat, tfd.Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhats = [model(val_input) for _ in range(100)]\n",
    "for i, yhat in enumerate(yhats):\n",
    "  m = np.squeeze(yhat.mean())\n",
    "  s = np.squeeze(yhat.stddev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dates = np.array(df.iloc[sequence_length+train_size:,0]).T.reshape(-1,1)\n",
    "print(val_dates.shape,y2.shape,m.shape)\n",
    "upper_bound = m + s\n",
    "lower_bound = m - s\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(val_dates,y2, label='True Values', color='black')\n",
    "plt.plot(val_dates,m, label='Predicted Mean', color='red')\n",
    "plt.fill_between(val_dates.reshape(-1), lower_bound, upper_bound, color='orange', alpha=0.3, label='Uncertainty Interval')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.title(f'{name} Predictions with Uncertainties')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "# plt.xlim((val_dates[50][0],val_dates[350][0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = -80\n",
    "test_input = np.lib.stride_tricks.sliding_window_view(df.iloc[test_size:-1,1].values, sequence_length)\n",
    "y3 = np.array(df.iloc[sequence_length+test_size:,1]).T.astype(np.float32).reshape(-1,1)\n",
    "y3shift = np.roll(y3, shift=1)\n",
    "y3shift[0] = np.nan\n",
    "test_dates = np.array(df.iloc[sequence_length+test_size:,0]).T.reshape(-1,1)\n",
    "\n",
    "yhats_test = [model(test_input) for _ in range(100)]\n",
    "\n",
    "for i, yhat in enumerate(yhats_test):\n",
    "  m_test = np.squeeze(yhat.mean())\n",
    "  s_test = np.squeeze(yhat.stddev())\n",
    "\n",
    "print(test_input.shape,y3.shape,test_dates.shape,m_test.shape)\n",
    "upper_bound = m_test + s_test\n",
    "lower_bound = m_test - s_test\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(test_dates, y3, label='True Values', color='black',marker='o',markersize=3)\n",
    "plt.plot(test_dates, y3shift, label='Shift Values', color='grey')\n",
    "plt.plot(test_dates, m_test, label='Predicted Mean', color='red',marker='x',markersize=3)\n",
    "plt.fill_between(test_dates.reshape(-1), lower_bound, upper_bound, color='orange', alpha=0.3, label='Uncertainty Interval')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.title(f'{name} Predictions with Uncertainties')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def calculate_mape(true_data, forecast_data):\n",
    "    absolute_percentage_errors = np.abs((true_data - forecast_data) / true_data)\n",
    "    mape = np.mean(absolute_percentage_errors) * 100\n",
    "    return mape\n",
    "\n",
    "def calculate_rmse(true_data, forecast_data):\n",
    "    rmse = np.sqrt(mean_squared_error(true_data, forecast_data))\n",
    "    return rmse\n",
    "\n",
    "def calculate_mae(true_data, forecast_data):\n",
    "    mae = mean_absolute_error(true_data, forecast_data)\n",
    "    return mae\n",
    "\n",
    "def calculate_r2(true_data, forecast_data):\n",
    "    r2 = r2_score(true_data, forecast_data)\n",
    "    return r2\n",
    "\n",
    "def calculate_forecast_bias(true_data, forecast_data):\n",
    "    forecast_bias = np.mean(forecast_data - true_data)\n",
    "    return forecast_bias\n",
    "\n",
    "\n",
    "mape = calculate_mape(y3, m_test)\n",
    "rmse = calculate_rmse(y3, m_test)\n",
    "mae = calculate_mae(y3, m_test)\n",
    "fb = calculate_forecast_bias(y3, m_test)\n",
    "r2 = calculate_r2(y3, m_test)\n",
    "print(\"MAPE:\", mape,'\\nRMSE:',rmse,'\\nMAE:',mae,'\\nFB:',fb,'\\nR2:',r2)\n",
    "print()\n",
    "mape = calculate_mape(y3, np.nan_to_num(y3shift,nan=0.0))\n",
    "rmse = calculate_rmse(y3, np.nan_to_num(y3shift,nan=0.0))\n",
    "mae = calculate_mae(y3, np.nan_to_num(y3shift,nan=0.0))\n",
    "fb = calculate_forecast_bias(y3, np.nan_to_num(y3shift,nan=0.0))\n",
    "r2 = calculate_r2(y3, np.nan_to_num(y3shift,nan=0.0))\n",
    "print(\"MAPE:\", mape,'\\nRMSE:',rmse,'\\nMAE:',mae,'\\nFB:',fb,'\\nR2:',r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = y2.reshape(-1)\n",
    "print(y2.shape,m.shape)\n",
    "print(m.shape)\n",
    "true_pct_changes = (np.diff(y2) / y2[:-1]) * 100\n",
    "pred_pct_changes = ((m - y2) / y2) * 100 \n",
    "pred_pct_changes2 = (np.diff(m) / m[:-1]) * 100\n",
    "\n",
    "# y3 = y3.reshape(-1)\n",
    "# true_pct_changes = (np.diff(y3) / y3[:-1]) * 100\n",
    "# pred_pct_changes = ((m_test - y3) / y3) * 100 \n",
    "\n",
    "\n",
    "print(true_pct_changes.shape)\n",
    "print(pred_pct_changes.shape)\n",
    "plt.figure()\n",
    "plt.scatter(true_pct_changes, pred_pct_changes[:-1],color='orange',alpha=.4,label='Pred - Prev. Truth')\n",
    "plt.scatter(true_pct_changes, pred_pct_changes2,color='indigo',alpha=.4,label='Pred - Prev. Pred')\n",
    "plt.plot(true_pct_changes, true_pct_changes,lw=4,color='cadetblue')\n",
    "plt.axhline(y=0,ls='--',color='red')\n",
    "plt.axvline(x=0,ls='--',color='red')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4.5))\n",
    "plt.hist2d(true_pct_changes, pred_pct_changes[:-1], bins=25, cmap='jet',cmin=1)#,range=[[-2, 2], [-2, 2]]\n",
    "# plt.hist2d(true_pct_changes, pred_pct_changes2, bins=25, cmap='jet',range=[[-2, 2], [-2, 2]],cmin=1)\n",
    "plt.colorbar(label='Counts')\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('2D Histogram')\n",
    "plt.axhline(y=0, color='red', linestyle='-',lw=2.5)   # Horizontal line at y=0\n",
    "plt.axvline(x=0, color='red', linestyle='-',lw=2.5)  # Vertical line at x=0\n",
    "plt.plot(true_pct_changes, true_pct_changes, color='blue')   \n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(np.sign(true_pct_changes), np.sign(pred_pct_changes[:-1]), labels=[1, -1])\n",
    "# conf_matrix = confusion_matrix(np.sign(true_pct_changes), np.sign(pred_pct_changes2), labels=[1, -1])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "same_sign_indices = np.where(np.sign(true_pct_changes) == np.sign(pred_pct_changes[:-1]))\n",
    "diff_sign_indices = np.where(np.sign(true_pct_changes) != np.sign(pred_pct_changes[:-1]))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "_, bins, _ = plt.hist(true_pct_changes,bins=50,histtype='step',label='Actual Daily Returns')\n",
    "plt.hist(true_pct_changes[same_sign_indices],bins=bins,histtype='step',color='green',label='Correct')\n",
    "plt.hist(true_pct_changes[diff_sign_indices],bins=bins,histtype='step',color='red',label='Incorrect')\n",
    "plt.grid(color='0.95')\n",
    "plt.xlabel('Returns [%]')\n",
    "plt.title('Test set')\n",
    "x_min, x_max = plt.xlim()\n",
    "y_min, y_max = plt.ylim()\n",
    "text_x = x_min + 0.025 * (x_max - x_min)\n",
    "text_y = y_max - 0.1 * (y_max - y_min)\n",
    "plt.text(text_x, text_y, '% correct sign {:.3f}\\n% incorrect sign {:.3f}'.format(len(true_pct_changes[same_sign_indices])/len(true_pct_changes),\n",
    "                                                                                 len(true_pct_changes[diff_sign_indices])/len(true_pct_changes)), ha='left', va='top')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.cool)\n",
    "\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "cbar.ax.set_ylabel('Counts', rotation=-90, va=\"bottom\")\n",
    "ax.set(xlabel='Predicted labels',ylabel='True Labels')\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(['1', '-1'])\n",
    "ax.set_yticks([0,1])\n",
    "ax.set_yticklabels(['1', '-1'])\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(j, i, str(conf_matrix[i, j]), ha=\"center\", va=\"center\", color=\"white\" if conf_matrix[i, j] > conf_matrix.max() / 2 else \"black\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one day test\n",
    "one_day_input = np.lib.stride_tricks.sliding_window_view(df.iloc[-12:,1].values, sequence_length)[:-1]\n",
    "y4 = np.array(df.iloc[sequence_length-12:,1]).astype(np.float32)\n",
    "\n",
    "\n",
    "print(one_day_input)\n",
    "print(y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aleatoric uncertainty +- sigma\n",
    "#epistemic uncertainty 100 predict calls\n",
    "yhats_test = [model(one_day_input) for _ in range(100)]\n",
    "\n",
    "means = []\n",
    "stds = []\n",
    "avgm = np.zeros_like(one_day_input[...,0])\n",
    "for i, yhat in enumerate(yhats_test):\n",
    "  means.append(yhat.mean())\n",
    "  stds.append(yhat.stddev())\n",
    "  m_test = np.squeeze(yhat.mean())\n",
    "  s_test = np.squeeze(yhat.stddev())\n",
    "  avgm += m_test/len(yhats_test)\n",
    "\n",
    "mean_array = np.mean(np.array(means),axis=0)\n",
    "std_array = np.mean(np.array(stds),axis=0)\n",
    "print(mean_array)\n",
    "print(std_array)\n",
    "print(avgm)\n",
    "# print(means)\n",
    "print('Pred: ',m_test,'+-',s_test)\n",
    "upper_bound = m_test + s_test\n",
    "lower_bound = m_test - s_test\n",
    "# print(m_test, '+-', s_test)\n",
    "print('Truth: ',y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "plt.hist(s,bins=50)\n",
    "plt.xlabel('Model Uncertainty $\\sigma$')\n",
    "plt.title('Test Set')\n",
    "plt.grid(color='0.95')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pct_changes = (np.diff(y2) / y2[:-1]) * 100\n",
    "pred_pct_changes = (((m - y2) / y2) * 100 )[:-1]\n",
    "pred_pct_changes2 = (np.diff(m) / m[:-1]) * 100\n",
    "print(pred_pct_changes.shape,pred_pct_changes2.shape,true_pct_changes.shape)\n",
    "\n",
    "sig_cut = 4\n",
    "true_pct_changes_sig = true_pct_changes[s[:-1]<sig_cut]\n",
    "pred_pct_changes_sig = pred_pct_changes[s[:-1]<sig_cut]\n",
    "pred_pct_changes2_sig = pred_pct_changes2[s[:-1]<sig_cut]\n",
    "print(pred_pct_changes_sig.shape,pred_pct_changes2_sig.shape,true_pct_changes_sig.shape)\n",
    "plt.figure()\n",
    "plt.scatter(true_pct_changes_sig, pred_pct_changes_sig,color='orange',alpha=.4,label='Pred - Prev. Truth')\n",
    "# plt.scatter(true_pct_changes_sig, pred_pct_changes2_sig,color='indigo',alpha=.4,label='Pred - Prev. Pred')\n",
    "plt.plot(true_pct_changes_sig, true_pct_changes_sig,lw=4,color='cadetblue')\n",
    "plt.axhline(y=0,ls='--',color='red')\n",
    "plt.axvline(x=0,ls='--',color='red')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(true_pct_changes[:10])\n",
    "print(pred_pct_changes[:10])\n",
    "same_sign_indices = np.where(np.sign(true_pct_changes_sig) == np.sign(pred_pct_changes_sig))\n",
    "diff_sign_indices = np.where(np.sign(true_pct_changes_sig) != np.sign(pred_pct_changes_sig))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "_, bins, _ = plt.hist(true_pct_changes_sig,bins=50,histtype='step',label='Actual Daily Returns')\n",
    "plt.hist(true_pct_changes[same_sign_indices],bins=bins,histtype='step',color='green',label='Correct')\n",
    "plt.hist(true_pct_changes[diff_sign_indices],bins=bins,histtype='step',color='red',label='Incorrect')\n",
    "plt.grid(color='0.95')\n",
    "plt.xlabel('Returns [%]')\n",
    "plt.title(f'Test set (Post Cut) {sig_cut}')\n",
    "x_min, x_max = plt.xlim()\n",
    "y_min, y_max = plt.ylim()\n",
    "text_x = x_min + 0.025 * (x_max - x_min)\n",
    "text_y = y_max - 0.1 * (y_max - y_min)\n",
    "plt.text(text_x, text_y, '% correct sign {:.3f}\\n% incorrect sign {:.3f}'.format(len(true_pct_changes_sig[same_sign_indices])/len(true_pct_changes_sig),\n",
    "                                                                                 len(true_pct_changes_sig[diff_sign_indices])/len(true_pct_changes_sig)), ha='left', va='top')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
