{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas_ta\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spy_ohlc_df = yf.download('SPY', start='1999-02-01', end='2019-12-01')\n",
    "# spy_ohlc_df = yf.download('SPY', start='2019-01-01', end='2023-12-01')\n",
    "spy_ohlc_df = yf.download('MSFT', start='2019-01-01', end='2023-12-01')\n",
    "df = spy_ohlc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_ohlc_df['1d_close_pct'] = spy_ohlc_df['Close'].pct_change(1)\n",
    "spy_ohlc_df['2d_close_pct'] = spy_ohlc_df['Close'].pct_change(2)\n",
    "spy_ohlc_df['3d_close_pct'] = spy_ohlc_df['Close'].pct_change(3)\n",
    "spy_ohlc_df['4d_close_pct'] = spy_ohlc_df['Close'].pct_change(4)\n",
    "spy_ohlc_df['5d_close_pct'] = spy_ohlc_df['Close'].pct_change(5)\n",
    "spy_ohlc_df['10d_close_pct'] = spy_ohlc_df['Close'].pct_change(10)\n",
    "spy_ohlc_df['5d_future_close'] = spy_ohlc_df['Close'].shift(-1)\n",
    "spy_ohlc_df['5d_future_close_pct'] = spy_ohlc_df['5d_future_close'].pct_change(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_ohlc_df['10d_volatility'] = spy_ohlc_df['Close'].rolling(window=10).std()\n",
    "tr_df = pd.DataFrame()\n",
    "tr_df['High-Low'] = spy_ohlc_df['High'] - spy_ohlc_df['Low']\n",
    "tr_df['High-ClosePrev'] = abs(spy_ohlc_df['High'] - spy_ohlc_df['Close'].shift(1))\n",
    "tr_df['Low-ClosePrev'] = abs(spy_ohlc_df['Low'] - spy_ohlc_df['Close'].shift(1))\n",
    "spy_ohlc_df['TR'] = tr_df[['High-Low', 'High-ClosePrev', 'Low-ClosePrev']].max(axis=1)\n",
    "spy_ohlc_df['ATR10'] = spy_ohlc_df['TR'].rolling(window=10).mean()\n",
    "spy_ohlc_df['WATR'] = spy_ohlc_df['TR'].rolling(window=14).apply(lambda x: np.average(x, weights=np.arange(1, 14 + 1))) # Weighted Average True Range (WATR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_ohlc_df['SMA20'] = spy_ohlc_df.Close.rolling(20).mean()\n",
    "spy_ohlc_df['EMA20'] = spy_ohlc_df.Close.ewm(span=20).mean()\n",
    "spy_ohlc_df['SMA50'] = spy_ohlc_df.Close.rolling(50).mean()\n",
    "spy_ohlc_df['EMA50'] = spy_ohlc_df.Close.ewm(span=50).mean()\n",
    "spy_ohlc_df['SMA100'] = spy_ohlc_df.Close.rolling(100).mean()\n",
    "spy_ohlc_df['EMA100'] = spy_ohlc_df.Close.ewm(span=100).mean()\n",
    "\n",
    "spy_ohlc_df['RSI_14'] = pandas_ta.rsi(spy_ohlc_df['Close'],length=14)\n",
    "spy_ohlc_df['RSI_100'] = pandas_ta.rsi(spy_ohlc_df['Close'],length=100)\n",
    "\n",
    "vor_df = pandas_ta.vortex(spy_ohlc_df['High'],spy_ohlc_df['Low'],spy_ohlc_df['Close'],14)\n",
    "spy_ohlc_df['VTXP_14'] = vor_df['VTXP_14']\n",
    "spy_ohlc_df['VTXM_14'] = vor_df['VTXM_14']\n",
    "stoch_df = pandas_ta.stoch(spy_ohlc_df['High'],spy_ohlc_df['Low'],spy_ohlc_df['Close'],k=14,d=26)\n",
    "spy_ohlc_df['STOCHk_14_26_3'] = stoch_df['STOCHk_14_26_3']\n",
    "spy_ohlc_df['STOCHd_14_26_3'] = stoch_df['STOCHd_14_26_3']\n",
    "adx_df = pandas_ta.adx(spy_ohlc_df['High'],spy_ohlc_df['Low'],spy_ohlc_df['Close'],length=14)#average directional index\n",
    "spy_ohlc_df['ADX_14'] = adx_df['ADX_14']\n",
    "spy_ohlc_df['DMP_14'] = adx_df['DMP_14']\n",
    "spy_ohlc_df['DMN_14'] = adx_df['DMN_14']\n",
    "amat_df = pandas_ta.amat(spy_ohlc_df['Close']) #Archer Moving Averages Trends\n",
    "spy_ohlc_df['AMATe_LR_8_21_2'] = amat_df['AMATe_LR_8_21_2']\n",
    "spy_ohlc_df['AMATe_SR_8_21_2'] = amat_df['AMATe_SR_8_21_2']\n",
    "aroon_df = pandas_ta.aroon(spy_ohlc_df['High'],spy_ohlc_df['Low']) #Aroon & Aroon Oscillator\n",
    "spy_ohlc_df['AROOND_14'] = aroon_df['AROOND_14']\n",
    "spy_ohlc_df['AROONU_14'] = aroon_df['AROONU_14']\n",
    "spy_ohlc_df['AROONOSC_14'] = aroon_df['AROONOSC_14']\n",
    "psar_df = pandas_ta.psar(spy_ohlc_df['High'],spy_ohlc_df['Low'],spy_ohlc_df['Close']) #Parabolic Stop and Reverse\n",
    "# spy_ohlc_df['PSARl_0.02_0.2'] = psar_df['PSARl_0.02_0.2']\n",
    "# spy_ohlc_df['PSARs_0.02_0.2'] = psar_df['PSARs_0.02_0.2']\n",
    "spy_ohlc_df['PSARaf_0.02_0.2'] = psar_df['PSARaf_0.02_0.2']\n",
    "spy_ohlc_df['PSARr_0.02_0.2'] = psar_df['PSARr_0.02_0.2']\n",
    "ao_df = pandas_ta.ao(spy_ohlc_df['High'],spy_ohlc_df['Low'])#Awesome Oscillator\n",
    "spy_ohlc_df['AO_5_34'] = ao_df\n",
    "uo_df = pandas_ta.uo(spy_ohlc_df['High'],spy_ohlc_df['Low'],spy_ohlc_df['Close'])#Ultimate Oscillator\n",
    "spy_ohlc_df['UO_7_14_28'] = uo_df\n",
    "cg_df = pandas_ta.cg(spy_ohlc_df['Close'])#Center of Gravity\n",
    "spy_ohlc_df['CG_10'] = cg_df\n",
    "coppock_df = pandas_ta.coppock(spy_ohlc_df['Close'])#Coppock\n",
    "spy_ohlc_df['COPC_11_14_10'] = coppock_df\n",
    "inertia_df = pandas_ta.inertia(spy_ohlc_df['Close'],spy_ohlc_df['High'],spy_ohlc_df['Low'])#inertia\n",
    "spy_ohlc_df['INERTIA_20_14'] = inertia_df\n",
    "stc_df = pandas_ta.stc(spy_ohlc_df['Close']) #schaff trend cycle\n",
    "spy_ohlc_df['STC_10_12_26_0.5'] = stc_df['STC_10_12_26_0.5']\n",
    "spy_ohlc_df['STCmacd_10_12_26_0.5'] = stc_df['STCmacd_10_12_26_0.5']\n",
    "spy_ohlc_df['STCstoch_10_12_26_0.5'] = stc_df['STCstoch_10_12_26_0.5']\n",
    "tsi_df = pandas_ta.tsi(spy_ohlc_df['Close']) # true strength index\n",
    "spy_ohlc_df['TSI_13_25_13'] = tsi_df['TSI_13_25_13']\n",
    "qstick_df = pandas_ta.qstick(spy_ohlc_df['Open'],spy_ohlc_df['Close']) #q stick indicator\n",
    "spy_ohlc_df['QS_10'] = qstick_df\n",
    "vhf_df = pandas_ta.vhf(spy_ohlc_df['Close'])#vertical horizontal filter\n",
    "spy_ohlc_df['VHF_28'] = vhf_df\n",
    "dpo_df = pandas_ta.dpo(spy_ohlc_df['Close']) #detrend price oscillator\n",
    "spy_ohlc_df['DPO_20'] = dpo_df\n",
    "pdist_df = pandas_ta.pdist(spy_ohlc_df['Open'],spy_ohlc_df['High'],spy_ohlc_df['Low'],spy_ohlc_df['Close'])\n",
    "spy_ohlc_df['PDIST'] = pdist_df\n",
    "rvi_df = pandas_ta.rvi(spy_ohlc_df['Close'],spy_ohlc_df['High'],spy_ohlc_df['Low']) #relative volatility index\n",
    "spy_ohlc_df['RVI_14'] = rvi_df\n",
    "willr_df = pandas_ta.willr(spy_ohlc_df['High'],spy_ohlc_df['Low'],spy_ohlc_df['Close']) # William's Percent R (WILLR)\n",
    "spy_ohlc_df['WILLR_14'] = willr_df\n",
    "ebsw_df = pandas_ta.ebsw(spy_ohlc_df['Close']) #Even Better SineWave (EBSW)\n",
    "spy_ohlc_df['EBSW_40_10'] = ebsw_df\n",
    "kurt_df = pandas_ta.kurtosis(spy_ohlc_df['Close']) #kurtosis\n",
    "spy_ohlc_df['KURT_30'] = kurt_df\n",
    "zscore_df = pandas_ta.zscore(spy_ohlc_df['Close'])\n",
    "spy_ohlc_df['ZS_30'] = zscore_df\n",
    "chop_df = pandas_ta.chop(spy_ohlc_df['High'],spy_ohlc_df['Low'],spy_ohlc_df['Close']) #choppiness index\n",
    "spy_ohlc_df['CHOP_14_1_100'] = chop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spy_ohlc_df.shape)\n",
    "spy_ohlc_df = spy_ohlc_df.dropna()\n",
    "print(spy_ohlc_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = spy_ohlc_df.sample(frac=0.8,random_state=0)\n",
    "test_dataset = spy_ohlc_df.drop(train_dataset.index)\n",
    "train_dataset = train_dataset.drop('5d_future_close', axis=1)\n",
    "test_dataset = test_dataset.drop('5d_future_close', axis=1)\n",
    "\n",
    "train_labels = train_dataset.pop('5d_future_close_pct')\n",
    "test_labels = test_dataset.pop('5d_future_close_pct')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "normed_train_data = pd.DataFrame(scaler.fit_transform(train_dataset), columns=train_dataset.columns)\n",
    "normed_test_data = pd.DataFrame(scaler.fit_transform(test_dataset), columns=test_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history: tf.keras.callbacks.History) -> None:\n",
    "    \"\"\"\n",
    "    Plot training vs validation MAE and MSE over epoch.\n",
    "    \"\"\"\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    f,a = plt.subplots(1,3,figsize=(12,3))\n",
    "    a[0].plot(hist['epoch'], hist['mae'],label='Train Error')\n",
    "    a[0].plot(hist['epoch'], hist['val_mae'],label = 'Val Error')\n",
    "    a[0].set(xlabel='Epoch',ylabel='MAE')\n",
    "    a[0].legend()\n",
    "\n",
    "    a[1].plot(hist['epoch'], hist['mse'],label='Train Error')\n",
    "    a[1].plot(hist['epoch'], hist['val_mse'],label = 'Val Error')\n",
    "    a[1].set(xlabel='Epoch',ylabel='MSE')\n",
    "    a[1].legend()\n",
    "\n",
    "    a[2].plot(hist['epoch'], hist['loss'],label='Train Error')\n",
    "    a[2].plot(hist['epoch'], hist['val_loss'],label = 'Val Error')\n",
    "    a[2].set(xlabel='Epoch',ylabel='Loss func.')\n",
    "    a[2].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_mean_field(kernel_size, bias_size, dtype) -> tf.keras.Model:\n",
    "    \"\"\"Specify the surrogate posterior over `keras.layers.Dense` `kernel` and `bias`.\"\"\"\n",
    "    n = kernel_size + bias_size\n",
    "    c = np.log(np.expm1(1.))\n",
    "    \n",
    "    return tf.keras.Sequential([tfp.layers.VariableLayer(2 * n, dtype=dtype),\n",
    "                                tfp.layers.DistributionLambda(lambda t: tfd.Independent(tfd.Normal(loc=t[..., :n],\n",
    "                                                              scale=1e-5 + tf.nn.softplus(c + t[..., n:])),\n",
    "                                                              reinterpreted_batch_ndims=1)),])\n",
    "\n",
    "\n",
    "def prior_trainable(kernel_size, bias_size, dtype) -> tf.keras.Model:\n",
    "    \"\"\"Specify the prior over `keras.layers.Dense` `kernel` and `bias`.\"\"\"\n",
    "    n = kernel_size + bias_size\n",
    "    return tf.keras.Sequential([tfp.layers.VariableLayer(n, dtype=dtype),  # Returns a trainable variable of shape n, regardless of input\n",
    "                                tfp.layers.DistributionLambda(lambda t: tfd.Independent(tfd.Normal(loc=t, scale=1),reinterpreted_batch_ndims=1)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_penalty_term(y_true, y_pred):\n",
    "    # penalty = 1e-5\n",
    "    # loss = tf.where(tf.less(y_true * y_pred, 0), penalty * abs(y_pred) * tf.square(y_true - y_pred), tf.square(y_true - y_pred))\n",
    "    penalty = 10.5\n",
    "    loss = tf.where(tf.less(y_true * y_pred, 0), penalty * tf.square(y_true - y_pred), tf.square(y_true - y_pred))\n",
    "    return tf.reduce_mean(loss, axis=-1)\n",
    "\n",
    "def custom_activity_regularizer(weights, alpha=10.0):\n",
    "    return alpha * tf.reduce_sum(tf.square(weights))\n",
    "\n",
    "def build_model() -> tf.keras.Model:\n",
    "    model = keras.Sequential([\n",
    "        tfp.layers.DenseVariational(64, activation='relu', \n",
    "                                    input_shape=[len(train_dataset.keys())], \n",
    "                                    make_posterior_fn=posterior_mean_field, \n",
    "                                    make_prior_fn=prior_trainable,),\n",
    "\n",
    "        tfp.layers.DenseVariational(64, activation='relu', \n",
    "                                    activity_regularizer=custom_activity_regularizer,\n",
    "                                    make_posterior_fn=posterior_mean_field, \n",
    "                                    make_prior_fn=prior_trainable,),\n",
    " \n",
    "        layers.Dense(24,kernel_regularizer=tf.keras.regularizers.l2(1.0)),\n",
    "        layers.Dense(1),\n",
    "        ])\n",
    "\n",
    "    # optimizer = tf.keras.optimizers.legacy.RMSprop(0.001)\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "    # optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.001,momentum=0.9)\n",
    "\n",
    "    model.compile(loss=mse_penalty_term,#'mse',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "history = model.fit(\n",
    "    normed_train_data, \n",
    "    train_labels,\n",
    "    epochs=EPOCHS, \n",
    "    validation_split = 0.4, \n",
    "    verbose=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df['epoch'] = history.epoch\n",
    "hist_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1, mae1, mse1 = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
    "print(\"Testing set Mean Abs Error: {:5.2f}\".format(mae1))\n",
    "train_predictions1 = model.predict(normed_train_data).flatten()\n",
    "test_predictions1 = model.predict(normed_test_data).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = np.array(test_predictions1) - np.array(test_labels)\n",
    "same_sign_indices = np.where(np.sign(test_predictions1) == np.sign(test_labels))\n",
    "diff_sign_indices = np.where(np.sign(test_predictions1) != np.sign(test_labels))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "_, bins, _ = plt.hist(residuals,bins=50,histtype='step')\n",
    "plt.hist(residuals[same_sign_indices],bins=bins,histtype='step',color='green')\n",
    "plt.hist(residuals[diff_sign_indices],bins=bins,histtype='step',color='red')\n",
    "plt.grid(color='0.95')\n",
    "plt.xlabel('prediction - truth')\n",
    "plt.title('Test set')\n",
    "x_min, x_max = plt.xlim()\n",
    "y_min, y_max = plt.ylim()\n",
    "text_x = x_min + 0.025 * (x_max - x_min)\n",
    "text_y = y_max - 0.1 * (y_max - y_min)\n",
    "plt.text(text_x, text_y, '% correct sign {:.3f}\\n% incorrect sign {:.3f}'.format(len(residuals[same_sign_indices])/len(residuals),\n",
    "                                                                                 len(residuals[diff_sign_indices])/len(residuals)), ha='left', va='top')\n",
    "plt.savefig('bnn-sign-hist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plt.axes()\n",
    "plt.scatter(train_labels, train_predictions1,color='blue',label='train',alpha=.4)\n",
    "plt.scatter(test_labels, test_predictions1,color='orange',label='test',alpha=.7)\n",
    "plt.plot(test_labels, test_labels,lw=4,color='cadetblue')\n",
    "plt.plot(train_labels, train_labels,lw=2,color='cadetblue')\n",
    "plt.axhline(y=0,ls='--',color='red')\n",
    "plt.axvline(x=0,ls='--',color='red')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.legend()\n",
    "plt.savefig('bnn-scatter.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "_, bins, _ = plt.hist(test_predictions1,bins=50,histtype='step',color='red',label='Preds')\n",
    "plt.hist(test_labels,bins=bins,histtype='step',color='green',label='Truth')\n",
    "plt.grid(color='0.95')\n",
    "plt.xlabel('5d_future_close_pct')\n",
    "plt.title('Test set')\n",
    "plt.legend()\n",
    "# plt.savefig('bnn-pred-hist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(3,2))\n",
    "# plt.hist2d(test_labels, test_predictions1, bins=20, cmap='Blues')\n",
    "# plt.axhline(y=0,ls='--',color='red')\n",
    "# plt.axvline(x=0,ls='--',color='red')\n",
    "# plt.xlabel('Truth')\n",
    "# plt.ylabel('Predictions')\n",
    "# plt.title('Test Predictions')\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions1 = model.predict(normed_test_data).flatten()\n",
    "# print(test_predictions1[:15])\n",
    "# print(test_labels[:15])\n",
    "# normed_test_data['yhat'] = test_predictions1\n",
    "# normed_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a list comprehension to predict over each test instance 100 times.\n",
    "yhats = [model.predict(normed_test_data).flatten() for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "scat_xs, scat_ys = [], []\n",
    "viol_xs, viol_ys = [], []\n",
    "n=3\n",
    "for i in np.arange(n,n+5):\n",
    "    viol_ys.append(np.array(yhats)[:, i])\n",
    "    scat_xs.append(normed_test_data.index.values[i])\n",
    "    scat_ys.append(test_labels.values[i])\n",
    "    viol_xs.append(normed_test_data.index.values[i])\n",
    "\n",
    "ax.scatter(scat_xs, scat_ys,color='green',label='Truth')\n",
    "violin = ax.violinplot(viol_ys,positions=viol_xs,showmeans=True,showmedians=True)\n",
    "for pc in violin[\"bodies\"]:\n",
    "    pc.set(facecolor=\"grey\",edgecolor=\"black\",alpha=0.3)\n",
    "\n",
    "violin['cbars'].set(ec='black',lw=0.5,alpha=0.7)\n",
    "violin['cmins'].set(ec='red',lw=0.5,alpha=0.5)\n",
    "violin['cmaxes'].set(ec='red',lw=0.5,alpha=0.5)\n",
    "violin['cmeans'].set(ec='black',lw=1)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.set(xlabel='Date',ylabel='3d_future_close_pct')\n",
    "ax.grid(color=\"0.95\")\n",
    "legend_elements = [matplotlib.lines.Line2D([0], [0], marker='o', label='Truth',markerfacecolor='g', markersize=10,linestyle='None'),\n",
    "                   matplotlib.patches.Patch(facecolor='grey', edgecolor='k',label='Models dist.')]\n",
    "\n",
    "ax.legend(handles=legend_elements,loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 17\n",
    "array_2d = np.array(yhats)\n",
    "i_entries = array_2d[:, idx]\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(i_entries, bins=50,label='Model Preds')\n",
    "plt.axvline(x=test_labels[idx],color='red',ls='--',label='Truth')\n",
    "plt.axvline(x=np.mean(i_entries),color='green',ls='--',label='Models Mean')\n",
    "plt.axvline(x=np.median(i_entries),color='blue',ls='--',label='Models Median')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "correct_sign = []\n",
    "correct_sign2 = []\n",
    "for i in range(normed_test_data.shape[0]):\n",
    "    model_scores = array_2d[:, i]\n",
    "    mean_score = np.mean(model_scores)\n",
    "    med_score = np.median(model_scores)\n",
    "    if np.sign(mean_score) == np.sign(test_labels[i]):\n",
    "        correct_sign.append(1)\n",
    "    if np.sign(med_score) == np.sign(test_labels[i]):\n",
    "        correct_sign2.append(1)\n",
    "    else:\n",
    "        correct_sign.append(0)\n",
    "        correct_sign2.append(0)\n",
    "print(sum(correct_sign))\n",
    "print(sum(correct_sign2))\n",
    "print(sum(np.where(test_labels>0,1,0)),'/',len(test_labels))\n",
    "print(sum(np.where(test_labels>0,1,0))/len(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "batch = 16\n",
    "n_preds = 3\n",
    "# print(df['5d_future_close_pct'].values[n_preds*batch:n_preds*(batch+1)])\n",
    "# print('trut',test_labels.values[n_preds*batch:n_preds*(batch+1)])\n",
    "# print('pred',test_predictions1[n_preds*batch:n_preds*(batch+1)])\n",
    "# print('pmea',[np.mean(x) for x in yhats[n_preds*batch:n_preds*(batch+1)]])\n",
    "ax.scatter(normed_test_data.index.values[n_preds*batch:n_preds*(batch+1)], test_labels.values[n_preds*batch:n_preds*(batch+1)],color='green',label='Truth')\n",
    "# ax.scatter(normed_test_data.index.values[n_preds*batch:n_preds*(batch+1)], test_predictions1[n_preds*batch:n_preds*(batch+1)],marker='x',color='red',label='Model1')\n",
    "# violin = ax.violinplot(yhats[5*batch:5*(batch+1)],positions=df.index.values[5*batch:5*(batch+1)],showmeans=True)\n",
    "violin = ax.violinplot(yhats[n_preds*batch:n_preds*(batch+1)],positions=matplotlib.dates.date2num(normed_test_data.index)[n_preds*batch:n_preds*(batch+1)],showmeans=True,showmedians=True)\n",
    "for pc in violin[\"bodies\"]:\n",
    "    pc.set_facecolor(\"grey\")\n",
    "    pc.set_edgecolor(\"black\")\n",
    "    pc.set_alpha(0.3)\n",
    "\n",
    "violin['cbars'].set(ec='black',lw=0.5,alpha=0.7)\n",
    "violin['cmins'].set(ec='red',lw=0.5,alpha=0.5)\n",
    "violin['cmaxes'].set(ec='red',lw=0.5,alpha=0.5)\n",
    "violin['cmeans'].set(ec='black',lw=1)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.set(xlabel='Date',ylabel='3d_future_close_pct')\n",
    "ax.grid(color=\"0.95\")\n",
    "legend_elements = [matplotlib.lines.Line2D([0], [0], marker='o', label='Truth',markerfacecolor='g', markersize=10,linestyle='None'),\n",
    "                #    matplotlib.lines.Line2D([0], [0], marker='x', color='red', label='Model1', markersize=10,linestyle='None'),\n",
    "                   matplotlib.patches.Patch(facecolor='grey', edgecolor='k',label='Models dist.')]\n",
    "\n",
    "ax.legend(handles=legend_elements,loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normed_test_data.columns)\n",
    "# print(normed_test_data.head())\n",
    "print(normed_test_data.index.values[:5])\n",
    "\n",
    "# plt.violinplot(yhats[:5],positions=normed_test_data.index[:5],showmeans=True)\n",
    "plt.violinplot(yhats[:10],showmeans=True)\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Basic Violin Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/probability/examples/STS_approximate_inference_for_models_with_non_Gaussian_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = keras.Sequential([layers.Dense(128,activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.1)),\n",
    "                             layers.Dense(128,activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.1)),\n",
    "                             layers.Dense(64,activation='relu'),\n",
    "                             layers.Dense(32,activation='relu'),\n",
    "                             layers.Dense(1)])\n",
    "\n",
    "# optimizer = tf.keras.optimizers.legacy.RMSprop(0.001)\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.001,momentum=0.9)\n",
    "\n",
    "model_nn.compile(loss=mse_penalty_term,#'mse',\n",
    "                    optimizer=optimizer,\n",
    "                    metrics=['mae', 'mse'])\n",
    "model_nn.build(input_shape=normed_train_data.shape)\n",
    "model_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_nn = model_nn.fit(normed_train_data, \n",
    "                          train_labels,\n",
    "                          epochs=EPOCHS, \n",
    "                          validation_split = 0.3, \n",
    "                          verbose=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae, mse = model_nn.evaluate(normed_test_data, test_labels, verbose=2)\n",
    "print(\"Testing set Mean Abs Error: {:5.2f}\".format(mae))\n",
    "train_predictions = model_nn.predict(normed_train_data).flatten()\n",
    "test_predictions = model_nn.predict(normed_test_data).flatten()\n",
    "plot_history(history_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plt.axes()\n",
    "plt.scatter(train_labels, train_predictions,color='blue',label='train',alpha=.4)\n",
    "plt.scatter(test_labels, test_predictions,color='orange',label='test',alpha=.7)\n",
    "plt.plot(test_labels, test_labels,lw=4,color='cadetblue')\n",
    "plt.plot(train_labels, train_labels,lw=2,color='cadetblue')\n",
    "plt.axhline(y=0,ls='--',color='red')\n",
    "plt.axvline(x=0,ls='--',color='red')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.legend()\n",
    "# plt.savefig('ann-scatter.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
